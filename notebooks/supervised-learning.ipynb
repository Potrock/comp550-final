{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "import enum\n",
    "import json\n",
    "\n",
    "class EducationLevels(str, enum.Enum):\n",
    "    HIGH_SCHOOL = \"high_school\"\n",
    "    BACHELORS = \"bachelors\"\n",
    "    MASTERS = \"masters\"\n",
    "    PHD = \"phd\"\n",
    "    NONE = \"none\"\n",
    "\n",
    "class Location(BaseModel):\n",
    "    city: str\n",
    "    state_or_province: str\n",
    "    country: str\n",
    "\n",
    "class FakeProfile(BaseModel):\n",
    "    name: str\n",
    "    occupation: str\n",
    "    industry: str\n",
    "    job_description: str\n",
    "    education: EducationLevels\n",
    "    major: Optional[str] = Field(default=None)\n",
    "    location: Location\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, data: str):\n",
    "        return cls(**json.loads(data))\n",
    "\n",
    "class FakeProfiles(BaseModel):\n",
    "    profiles: List[FakeProfile]\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, data: str):\n",
    "        return cls(**json.loads(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWSGROUPS = [\n",
    "    'alt.atheism',\n",
    "    'comp.windows.x',\n",
    "    'misc.forsale',\n",
    "    'rec.autos',\n",
    "    'sci.med',\n",
    "    'rec.sport.hockey',\n",
    "    'sci.space',\n",
    "    'soc.religion.christian',\n",
    "    'talk.politics.guns'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load profiles data and store in a dataframe with their true labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>occupation</th>\n",
       "      <th>industry</th>\n",
       "      <th>job_description</th>\n",
       "      <th>education</th>\n",
       "      <th>major</th>\n",
       "      <th>location</th>\n",
       "      <th>news_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thomas Reed</td>\n",
       "      <td>Journalist</td>\n",
       "      <td>Media</td>\n",
       "      <td>Writes articles on various social topics, incl...</td>\n",
       "      <td>EducationLevels.BACHELORS</td>\n",
       "      <td>Journalism</td>\n",
       "      <td>{'city': 'Austin', 'state_or_province': 'Texas...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samantha Brooks</td>\n",
       "      <td>College Professor</td>\n",
       "      <td>Education</td>\n",
       "      <td>Teaches courses on philosophy, including metap...</td>\n",
       "      <td>EducationLevels.PHD</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>{'city': 'Berkeley', 'state_or_province': 'Cal...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marcus Li</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Develops mobile applications with a focus on s...</td>\n",
       "      <td>EducationLevels.BACHELORS</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>{'city': 'Seattle', 'state_or_province': 'Wash...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emily Nguyen</td>\n",
       "      <td>Human Rights Activist</td>\n",
       "      <td>NGO</td>\n",
       "      <td>Advocates for freedom of belief and expression...</td>\n",
       "      <td>EducationLevels.MASTERS</td>\n",
       "      <td>International Relations</td>\n",
       "      <td>{'city': 'New York', 'state_or_province': 'New...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jordan Smith</td>\n",
       "      <td>Blogger</td>\n",
       "      <td>Digital Media</td>\n",
       "      <td>Runs a popular blog discussing religion, athei...</td>\n",
       "      <td>EducationLevels.BACHELORS</td>\n",
       "      <td>English</td>\n",
       "      <td>{'city': 'Denver', 'state_or_province': 'Color...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name             occupation       industry  \\\n",
       "0      Thomas Reed             Journalist          Media   \n",
       "1  Samantha Brooks      College Professor      Education   \n",
       "2        Marcus Li     Software Developer     Technology   \n",
       "3     Emily Nguyen  Human Rights Activist            NGO   \n",
       "4     Jordan Smith                Blogger  Digital Media   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  Writes articles on various social topics, incl...   \n",
       "1  Teaches courses on philosophy, including metap...   \n",
       "2  Develops mobile applications with a focus on s...   \n",
       "3  Advocates for freedom of belief and expression...   \n",
       "4  Runs a popular blog discussing religion, athei...   \n",
       "\n",
       "                   education                    major  \\\n",
       "0  EducationLevels.BACHELORS               Journalism   \n",
       "1        EducationLevels.PHD               Philosophy   \n",
       "2  EducationLevels.BACHELORS         Computer Science   \n",
       "3    EducationLevels.MASTERS  International Relations   \n",
       "4  EducationLevels.BACHELORS                  English   \n",
       "\n",
       "                                            location   news_group  \n",
       "0  {'city': 'Austin', 'state_or_province': 'Texas...  alt.atheism  \n",
       "1  {'city': 'Berkeley', 'state_or_province': 'Cal...  alt.atheism  \n",
       "2  {'city': 'Seattle', 'state_or_province': 'Wash...  alt.atheism  \n",
       "3  {'city': 'New York', 'state_or_province': 'New...  alt.atheism  \n",
       "4  {'city': 'Denver', 'state_or_province': 'Color...  alt.atheism  "
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "profiles = []\n",
    "\n",
    "# Load the profiles from the json files\n",
    "for news_group in NEWSGROUPS:\n",
    "    \n",
    "    with open(f\"../fake_profiles/{news_group.replace('.', '_')}.json\", \"r\", encoding='utf-8') as f:\n",
    "        \n",
    "        # get profiles for current news group\n",
    "        profiles_group = FakeProfiles.from_json(f.read())\n",
    "        \n",
    "        # store all profiles in dataframe\n",
    "        for profile in profiles_group.profiles:\n",
    "            # convert profile to dict\n",
    "            profile_dict = profile.model_dump()\n",
    "            # add news group field (true label for profile)\n",
    "            profile_dict['news_group'] = news_group\n",
    "            profiles.append(profile_dict)\n",
    "            \n",
    "        \n",
    "df = pd.DataFrame(profiles)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for model fitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing text fields for each profile. Techniques include stopword removal and lemmatization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sevag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sevag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text_field(text):\n",
    "    # remove blanks and convert to lower case\n",
    "    if text is None:\n",
    "        return 'none'\n",
    "    else:\n",
    "        return text.lower().strip()\n",
    "\n",
    "# more preprocessing for job description\n",
    "def preprocess_job_description(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    lemmatized_text = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess fields and add back to the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>occupation</th>\n",
       "      <th>industry</th>\n",
       "      <th>job_description</th>\n",
       "      <th>education</th>\n",
       "      <th>major</th>\n",
       "      <th>location</th>\n",
       "      <th>news_group</th>\n",
       "      <th>job_description_preprocessed</th>\n",
       "      <th>city</th>\n",
       "      <th>state_or_province</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thomas Reed</td>\n",
       "      <td>journalist</td>\n",
       "      <td>media</td>\n",
       "      <td>Writes articles on various social topics, incl...</td>\n",
       "      <td>EducationLevels.BACHELORS</td>\n",
       "      <td>journalism</td>\n",
       "      <td>{'city': 'Austin', 'state_or_province': 'Texas...</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Writes article various social topic , includin...</td>\n",
       "      <td>austin</td>\n",
       "      <td>texas</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samantha Brooks</td>\n",
       "      <td>college professor</td>\n",
       "      <td>education</td>\n",
       "      <td>Teaches courses on philosophy, including metap...</td>\n",
       "      <td>EducationLevels.PHD</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>{'city': 'Berkeley', 'state_or_province': 'Cal...</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Teaches course philosophy , including metaphys...</td>\n",
       "      <td>berkeley</td>\n",
       "      <td>california</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marcus Li</td>\n",
       "      <td>software developer</td>\n",
       "      <td>technology</td>\n",
       "      <td>Develops mobile applications with a focus on s...</td>\n",
       "      <td>EducationLevels.BACHELORS</td>\n",
       "      <td>computer science</td>\n",
       "      <td>{'city': 'Seattle', 'state_or_province': 'Wash...</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Develops mobile application focus social netwo...</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emily Nguyen</td>\n",
       "      <td>human rights activist</td>\n",
       "      <td>ngo</td>\n",
       "      <td>Advocates for freedom of belief and expression...</td>\n",
       "      <td>EducationLevels.MASTERS</td>\n",
       "      <td>international relations</td>\n",
       "      <td>{'city': 'New York', 'state_or_province': 'New...</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Advocates freedom belief expression around wor...</td>\n",
       "      <td>new york</td>\n",
       "      <td>new york</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jordan Smith</td>\n",
       "      <td>blogger</td>\n",
       "      <td>digital media</td>\n",
       "      <td>Runs a popular blog discussing religion, athei...</td>\n",
       "      <td>EducationLevels.BACHELORS</td>\n",
       "      <td>english</td>\n",
       "      <td>{'city': 'Denver', 'state_or_province': 'Color...</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Runs popular blog discussing religion , atheis...</td>\n",
       "      <td>denver</td>\n",
       "      <td>colorado</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name             occupation       industry  \\\n",
       "0      Thomas Reed             journalist          media   \n",
       "1  Samantha Brooks      college professor      education   \n",
       "2        Marcus Li     software developer     technology   \n",
       "3     Emily Nguyen  human rights activist            ngo   \n",
       "4     Jordan Smith                blogger  digital media   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  Writes articles on various social topics, incl...   \n",
       "1  Teaches courses on philosophy, including metap...   \n",
       "2  Develops mobile applications with a focus on s...   \n",
       "3  Advocates for freedom of belief and expression...   \n",
       "4  Runs a popular blog discussing religion, athei...   \n",
       "\n",
       "                   education                    major  \\\n",
       "0  EducationLevels.BACHELORS               journalism   \n",
       "1        EducationLevels.PHD               philosophy   \n",
       "2  EducationLevels.BACHELORS         computer science   \n",
       "3    EducationLevels.MASTERS  international relations   \n",
       "4  EducationLevels.BACHELORS                  english   \n",
       "\n",
       "                                            location   news_group  \\\n",
       "0  {'city': 'Austin', 'state_or_province': 'Texas...  alt.atheism   \n",
       "1  {'city': 'Berkeley', 'state_or_province': 'Cal...  alt.atheism   \n",
       "2  {'city': 'Seattle', 'state_or_province': 'Wash...  alt.atheism   \n",
       "3  {'city': 'New York', 'state_or_province': 'New...  alt.atheism   \n",
       "4  {'city': 'Denver', 'state_or_province': 'Color...  alt.atheism   \n",
       "\n",
       "                        job_description_preprocessed      city  \\\n",
       "0  Writes article various social topic , includin...    austin   \n",
       "1  Teaches course philosophy , including metaphys...  berkeley   \n",
       "2  Develops mobile application focus social netwo...   seattle   \n",
       "3  Advocates freedom belief expression around wor...  new york   \n",
       "4  Runs popular blog discussing religion , atheis...    denver   \n",
       "\n",
       "  state_or_province country  \n",
       "0             texas     usa  \n",
       "1        california     usa  \n",
       "2        washington     usa  \n",
       "3          new york     usa  \n",
       "4          colorado     usa  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple preprocessing for occupation, industry, major\n",
    "text_fields = ['occupation', 'industry', 'major']\n",
    "for field in text_fields:\n",
    "    df[field] = df[field].apply(preprocess_text_field)\n",
    "    \n",
    "# preprocessing for job description\n",
    "df['job_description_preprocessed'] = df['job_description'].apply(preprocess_job_description)\n",
    "    \n",
    "# flatten location\n",
    "df['city'] = df['location'].apply(lambda x: preprocess_text_field(x['city']))\n",
    "df['state_or_province'] = df['location'].apply(lambda x: preprocess_text_field(x['state_or_province']))\n",
    "df['country'] = df['location'].apply(lambda x: preprocess_text_field(x['country']))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting models to the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract numerical and categorical features from the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# vectorization for job description\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_job_description = vectorizer.fit_transform(df['job_description_preprocessed'])\n",
    "\n",
    "# one-hot encoding for education\n",
    "X_education = pd.get_dummies(df['education'])\n",
    "\n",
    "X_occupation = CountVectorizer()\n",
    "\n",
    "# bag of words features\n",
    "bow_fields = ['occupation', 'industry', 'major', 'city', 'state_or_province', 'country']\n",
    "bow_features = {}\n",
    "for field in bow_fields:\n",
    "    vectorizer = CountVectorizer()\n",
    "    bow_features[field] = vectorizer.fit_transform(df[field])\n",
    "    \n",
    "# combine covariates\n",
    "X_job_description_sparse = sp.csr_matrix(X_job_description)\n",
    "X_categorical_sparse = sp.csr_matrix(X_education)\n",
    "X_combined = sp.hstack([X_job_description_sparse, X_categorical_sparse] + [bow_features[field] for field in bow_fields])\n",
    "\n",
    "# extract targets\n",
    "y = df['news_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we fit supervised machine learning models with multiclass outputs. The outputs correspond to news groups, and the probability that a given profile is relevant to each news group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression average prediction score: 0.29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# logistic regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000, random_state=1)\n",
    "\n",
    "# 6-fold cross validation\n",
    "cv_logistic = cross_val_score(logistic_model, X_combined, y, cv=6)\n",
    "print(f\"Logistic regression average prediction score: {cv_logistic.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes average prediction score: 0.28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# bernoulli bayes model (binary classification)\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# 6-fold cross validation\n",
    "cv_nb = cross_val_score(nb, X_combined, y, cv=6)\n",
    "print(f\"Naive Bayes average prediction score: {cv_nb.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree average prediction score: 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# 6-fold cross validation\n",
    "cv_dt = cross_val_score(dt, X_combined, y, cv=6)\n",
    "print(f\"Decision tree average prediction score: {cv_dt.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support vector machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM average prediction score: 0.28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(random_state=1)\n",
    "\n",
    "# 6-fold cross validation\n",
    "cv_svm = cross_val_score(svm, X_combined, y, cv=6)\n",
    "print(f\"SVM average prediction score: {cv_svm.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we fit supervised machine learning models with binary outputs. We train separate models for each news group. Each model tries to predict the relevance of a given profile to the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to predict a profile's relevance to each news group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_profile_relevance(features, category_models):\n",
    "    probs = {}\n",
    "    for news_group, model in category_models.items():\n",
    "        # get class probabilities from model\n",
    "        prob = model.predict(features)\n",
    "        probs[news_group] = prob\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract news group categories for the labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "176    0\n",
       "177    0\n",
       "178    0\n",
       "179    0\n",
       "180    0\n",
       "Name: news_group, Length: 181, dtype: int32"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label is 1 if profile belongs to the news group key, 0 otherwise\n",
    "binary_labels = {category: (df['news_group'] == category).astype(int) for category in NEWSGROUPS}\n",
    "binary_labels['alt.atheism']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression F1 for alt.atheism: 0.0000\n",
      "Logistic regression F1 for comp.windows.x: 0.0000\n",
      "Logistic regression F1 for misc.forsale: 0.0000\n",
      "Logistic regression F1 for rec.autos: 0.0000\n",
      "Logistic regression F1 for sci.med: 0.7500\n",
      "Logistic regression F1 for rec.sport.hockey: 0.0000\n",
      "Logistic regression F1 for sci.space: 0.0000\n",
      "Logistic regression F1 for soc.religion.christian: 0.0000\n",
      "Logistic regression F1 for talk.politics.guns: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "logistic_models_per_news_group = {}\n",
    "\n",
    "for news_group, labels in binary_labels.items():\n",
    "    \n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_combined, labels, test_size=0.2, random_state=1)\n",
    "    \n",
    "    # train model\n",
    "    lr_model = LogisticRegression(max_iter=1000)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # get predictions and accuracy\n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    \n",
    "    # get model accuracy\n",
    "    print(f'Logistic regression F1 for {news_group}: {f1_score(y_test, y_pred):0.4f}')\n",
    "    \n",
    "    # store model\n",
    "    logistic_models_per_news_group[news_group] = lr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1 for alt.atheism: 0.0000\n",
      "Naive Bayes F1 for comp.windows.x: 0.0000\n",
      "Naive Bayes F1 for misc.forsale: 0.0000\n",
      "Naive Bayes F1 for rec.autos: 0.0000\n",
      "Naive Bayes F1 for sci.med: 0.0000\n",
      "Naive Bayes F1 for rec.sport.hockey: 0.0000\n",
      "Naive Bayes F1 for sci.space: 0.0000\n",
      "Naive Bayes F1 for soc.religion.christian: 0.0000\n",
      "Naive Bayes F1 for talk.politics.guns: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "nb_models_per_news_group = {}\n",
    "\n",
    "for news_group, labels in binary_labels.items():\n",
    "    \n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_combined, labels, test_size=0.2, random_state=1)\n",
    "    \n",
    "    # train model\n",
    "    nb_model = BernoulliNB()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # get predictions and accuracy\n",
    "    y_pred = nb_model.predict(X_test)\n",
    "    \n",
    "    # get model accuracy\n",
    "    print(f'Naive Bayes F1 for {news_group}: {f1_score(y_test, y_pred):0.4f}')\n",
    "    \n",
    "    # store model\n",
    "    nb_models_per_news_group[news_group] = nb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree F1 for alt.atheism: 0.7692\n",
      "Decision tree F1 for comp.windows.x: 0.0000\n",
      "Decision tree F1 for misc.forsale: 0.2222\n",
      "Decision tree F1 for rec.autos: 0.0000\n",
      "Decision tree F1 for sci.med: 1.0000\n",
      "Decision tree F1 for rec.sport.hockey: 1.0000\n",
      "Decision tree F1 for sci.space: 0.4000\n",
      "Decision tree F1 for soc.religion.christian: 1.0000\n",
      "Decision tree F1 for talk.politics.guns: 0.5000\n"
     ]
    }
   ],
   "source": [
    "decision_tree_models_per_news_group = {}\n",
    "\n",
    "for news_group, labels in binary_labels.items():\n",
    "    \n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_combined, labels, test_size=0.2, random_state=1)\n",
    "    \n",
    "    # train model\n",
    "    dt_model = DecisionTreeClassifier(random_state=1)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    # get predictions and accuracy\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "    \n",
    "    # get model accuracy\n",
    "    print(f'Decision tree F1 for {news_group}: {f1_score(y_test, y_pred):0.4f}')\n",
    "    \n",
    "    # store model\n",
    "    decision_tree_models_per_news_group[news_group] = dt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM F1 for alt.atheism: 0.0000\n",
      "SVM F1 for comp.windows.x: 0.0000\n",
      "SVM F1 for misc.forsale: 0.0000\n",
      "SVM F1 for rec.autos: 0.0000\n",
      "SVM F1 for sci.med: 0.0000\n",
      "SVM F1 for rec.sport.hockey: 0.0000\n",
      "SVM F1 for sci.space: 0.0000\n",
      "SVM F1 for soc.religion.christian: 0.0000\n",
      "SVM F1 for talk.politics.guns: 0.0000\n"
     ]
    }
   ],
   "source": [
    "svm_models_per_news_group = {}\n",
    "\n",
    "for news_group, labels in binary_labels.items():\n",
    "    \n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_combined, labels, test_size=0.2, random_state=1)\n",
    "    \n",
    "    # train model\n",
    "    svm_model = SVC(random_state=1)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # get predictions and accuracy\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    # get model accuracy\n",
    "    print(f'SVM F1 for {news_group}: {f1_score(y_test, y_pred):0.4f}')\n",
    "    \n",
    "    # store model\n",
    "    svm_models_per_news_group[news_group] = svm_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
