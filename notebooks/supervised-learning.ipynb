{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "import enum\n",
    "import json\n",
    "\n",
    "class EducationLevels(str, enum.Enum):\n",
    "    HIGH_SCHOOL = \"high_school\"\n",
    "    BACHELORS = \"bachelors\"\n",
    "    MASTERS = \"masters\"\n",
    "    PHD = \"phd\"\n",
    "    NONE = \"none\"\n",
    "\n",
    "class Location(BaseModel):\n",
    "    city: str\n",
    "    state_or_province: str\n",
    "    country: str\n",
    "\n",
    "class FakeProfile(BaseModel):\n",
    "    name: str\n",
    "    occupation: str\n",
    "    industry: str\n",
    "    job_description: str\n",
    "    education: EducationLevels\n",
    "    major: Optional[str] = Field(default=None)\n",
    "    location: Location\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, data: str):\n",
    "        return cls(**json.loads(data))\n",
    "\n",
    "class FakeProfiles(BaseModel):\n",
    "    profiles: List[FakeProfile]\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, data: str):\n",
    "        return cls(**json.loads(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWSGROUPS = [\n",
    "    'alt.atheism',\n",
    "    'comp.windows.x',\n",
    "    'misc.forsale',\n",
    "    'rec.autos',\n",
    "    'sci.med',\n",
    "    'rec.sport.hockey',\n",
    "    'sci.space',\n",
    "    'soc.religion.christian',\n",
    "    'talk.politics.guns'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'sci.med', 'rec.sport.hockey', 'sci.space', 'soc.religion.christian', 'talk.politics.guns']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, random_state=2, return_X_y=True)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, random_state=2, return_X_y=True)\n",
    "\n",
    "num_articles_newsgroups_train = len(newsgroups_train[0])\n",
    "num_articles_newsgroups_test = len(newsgroups_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load profiles data, pair them with articles, and store in a dataframe with corresponding output (True/False depending on whether the article is relevant to the profile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>occupation</th>\n",
       "      <th>industry</th>\n",
       "      <th>job_description</th>\n",
       "      <th>education</th>\n",
       "      <th>major</th>\n",
       "      <th>location</th>\n",
       "      <th>article</th>\n",
       "      <th>is_relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thomas Reed</td>\n",
       "      <td>Journalist</td>\n",
       "      <td>Media</td>\n",
       "      <td>Writes articles on various social topics, incl...</td>\n",
       "      <td>EducationLevels.BACHELORS</td>\n",
       "      <td>Journalism</td>\n",
       "      <td>{'city': 'Austin', 'state_or_province': 'Texas...</td>\n",
       "      <td>From: bil@okcforum.osrhe.edu (Bill Conner)\\nSu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samantha Brooks</td>\n",
       "      <td>College Professor</td>\n",
       "      <td>Education</td>\n",
       "      <td>Teaches courses on philosophy, including metap...</td>\n",
       "      <td>EducationLevels.PHD</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>{'city': 'Berkeley', 'state_or_province': 'Cal...</td>\n",
       "      <td>From: lundby@rtsg.mot.com (Walter F. Lundby)\\n...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marcus Li</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Develops mobile applications with a focus on s...</td>\n",
       "      <td>EducationLevels.BACHELORS</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>{'city': 'Seattle', 'state_or_province': 'Wash...</td>\n",
       "      <td>From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emily Nguyen</td>\n",
       "      <td>Human Rights Activist</td>\n",
       "      <td>NGO</td>\n",
       "      <td>Advocates for freedom of belief and expression...</td>\n",
       "      <td>EducationLevels.MASTERS</td>\n",
       "      <td>International Relations</td>\n",
       "      <td>{'city': 'New York', 'state_or_province': 'New...</td>\n",
       "      <td>Subject: Space FAQ 01/15 - Introduction\\nFrom:...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jordan Smith</td>\n",
       "      <td>Blogger</td>\n",
       "      <td>Digital Media</td>\n",
       "      <td>Runs a popular blog discussing religion, athei...</td>\n",
       "      <td>EducationLevels.BACHELORS</td>\n",
       "      <td>English</td>\n",
       "      <td>{'city': 'Denver', 'state_or_province': 'Color...</td>\n",
       "      <td>From: mangoe@cs.umd.edu (Charley Wingate)\\nSub...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name             occupation       industry  \\\n",
       "0      Thomas Reed             Journalist          Media   \n",
       "1  Samantha Brooks      College Professor      Education   \n",
       "2        Marcus Li     Software Developer     Technology   \n",
       "3     Emily Nguyen  Human Rights Activist            NGO   \n",
       "4     Jordan Smith                Blogger  Digital Media   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  Writes articles on various social topics, incl...   \n",
       "1  Teaches courses on philosophy, including metap...   \n",
       "2  Develops mobile applications with a focus on s...   \n",
       "3  Advocates for freedom of belief and expression...   \n",
       "4  Runs a popular blog discussing religion, athei...   \n",
       "\n",
       "                   education                    major  \\\n",
       "0  EducationLevels.BACHELORS               Journalism   \n",
       "1        EducationLevels.PHD               Philosophy   \n",
       "2  EducationLevels.BACHELORS         Computer Science   \n",
       "3    EducationLevels.MASTERS  International Relations   \n",
       "4  EducationLevels.BACHELORS                  English   \n",
       "\n",
       "                                            location  \\\n",
       "0  {'city': 'Austin', 'state_or_province': 'Texas...   \n",
       "1  {'city': 'Berkeley', 'state_or_province': 'Cal...   \n",
       "2  {'city': 'Seattle', 'state_or_province': 'Wash...   \n",
       "3  {'city': 'New York', 'state_or_province': 'New...   \n",
       "4  {'city': 'Denver', 'state_or_province': 'Color...   \n",
       "\n",
       "                                             article  is_relevant  \n",
       "0  From: bil@okcforum.osrhe.edu (Bill Conner)\\nSu...         True  \n",
       "1  From: lundby@rtsg.mot.com (Walter F. Lundby)\\n...        False  \n",
       "2  From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...         True  \n",
       "3  Subject: Space FAQ 01/15 - Introduction\\nFrom:...        False  \n",
       "4  From: mangoe@cs.umd.edu (Charley Wingate)\\nSub...         True  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "profiles = []\n",
    "\n",
    "# Load the profiles from the json files\n",
    "for news_group in NEWSGROUPS:\n",
    "    \n",
    "    with open(f\"../fake_profiles/{news_group.replace('.', '_')}.json\", \"r\", encoding='utf-8') as f:\n",
    "        \n",
    "        # get profiles for current news group\n",
    "        profiles_group = FakeProfiles.from_json(f.read())\n",
    "        \n",
    "        # store all profiles in dataframe\n",
    "        for profile in profiles_group.profiles:\n",
    "            # convert profile to dict\n",
    "            profile_dict = profile.model_dump()\n",
    "\n",
    "            # get random article from train set\n",
    "            index = np.random.choice(num_articles_newsgroups_train)\n",
    "            random_article = newsgroups_train[0][index]\n",
    "            article_label = newsgroups_train[1][index]\n",
    "            \n",
    "            # determine whether article relevant (same category)\n",
    "            is_relevant = (article_label == categories.index(news_group))\n",
    "            \n",
    "            # attach article and is_relevant to profile\n",
    "            profile_dict['article'] = random_article\n",
    "            profile_dict['is_relevant'] = is_relevant\n",
    "            \n",
    "            # append profile to list           \n",
    "            profiles.append(profile_dict)\n",
    "            \n",
    "        \n",
    "df = pd.DataFrame(profiles)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for model fitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing text fields for each profile. Techniques include stopword removal and lemmatization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sevag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sevag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_shorter_text(text):\n",
    "    # remove blanks and convert to lower case\n",
    "    if text is None:\n",
    "        return 'none'\n",
    "    else:\n",
    "        return text.lower().strip()\n",
    "\n",
    "# more preprocessing for longer text\n",
    "def preprocess_longer_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    lemmatized_text = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess fields and add back to the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>occupation</th>\n",
       "      <th>industry</th>\n",
       "      <th>job_description</th>\n",
       "      <th>education</th>\n",
       "      <th>major</th>\n",
       "      <th>location</th>\n",
       "      <th>article</th>\n",
       "      <th>is_relevant</th>\n",
       "      <th>job_description_preprocessed</th>\n",
       "      <th>city</th>\n",
       "      <th>state_or_province</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thomas Reed</td>\n",
       "      <td>journalist</td>\n",
       "      <td>media</td>\n",
       "      <td>Writes articles on various social topics, incl...</td>\n",
       "      <td>EducationLevels.BACHELORS</td>\n",
       "      <td>journalism</td>\n",
       "      <td>{'city': 'Austin', 'state_or_province': 'Texas...</td>\n",
       "      <td>From : bil @ okcforum.osrhe.edu ( Bill Conner ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Writes article various social topic , includin...</td>\n",
       "      <td>austin</td>\n",
       "      <td>texas</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samantha Brooks</td>\n",
       "      <td>college professor</td>\n",
       "      <td>education</td>\n",
       "      <td>Teaches courses on philosophy, including metap...</td>\n",
       "      <td>EducationLevels.PHD</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>{'city': 'Berkeley', 'state_or_province': 'Cal...</td>\n",
       "      <td>From : lundby @ rtsg.mot.com ( Walter F. Lundb...</td>\n",
       "      <td>False</td>\n",
       "      <td>Teaches course philosophy , including metaphys...</td>\n",
       "      <td>berkeley</td>\n",
       "      <td>california</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marcus Li</td>\n",
       "      <td>software developer</td>\n",
       "      <td>technology</td>\n",
       "      <td>Develops mobile applications with a focus on s...</td>\n",
       "      <td>EducationLevels.BACHELORS</td>\n",
       "      <td>computer science</td>\n",
       "      <td>{'city': 'Seattle', 'state_or_province': 'Wash...</td>\n",
       "      <td>From : I3150101 @ dbstu1.rz.tu-bs.de ( Benedik...</td>\n",
       "      <td>True</td>\n",
       "      <td>Develops mobile application focus social netwo...</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emily Nguyen</td>\n",
       "      <td>human rights activist</td>\n",
       "      <td>ngo</td>\n",
       "      <td>Advocates for freedom of belief and expression...</td>\n",
       "      <td>EducationLevels.MASTERS</td>\n",
       "      <td>international relations</td>\n",
       "      <td>{'city': 'New York', 'state_or_province': 'New...</td>\n",
       "      <td>Subject : Space FAQ 01/15 - Introduction From ...</td>\n",
       "      <td>False</td>\n",
       "      <td>Advocates freedom belief expression around wor...</td>\n",
       "      <td>new york</td>\n",
       "      <td>new york</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jordan Smith</td>\n",
       "      <td>blogger</td>\n",
       "      <td>digital media</td>\n",
       "      <td>Runs a popular blog discussing religion, athei...</td>\n",
       "      <td>EducationLevels.BACHELORS</td>\n",
       "      <td>english</td>\n",
       "      <td>{'city': 'Denver', 'state_or_province': 'Color...</td>\n",
       "      <td>From : mangoe @ cs.umd.edu ( Charley Wingate )...</td>\n",
       "      <td>True</td>\n",
       "      <td>Runs popular blog discussing religion , atheis...</td>\n",
       "      <td>denver</td>\n",
       "      <td>colorado</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name             occupation       industry  \\\n",
       "0      Thomas Reed             journalist          media   \n",
       "1  Samantha Brooks      college professor      education   \n",
       "2        Marcus Li     software developer     technology   \n",
       "3     Emily Nguyen  human rights activist            ngo   \n",
       "4     Jordan Smith                blogger  digital media   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  Writes articles on various social topics, incl...   \n",
       "1  Teaches courses on philosophy, including metap...   \n",
       "2  Develops mobile applications with a focus on s...   \n",
       "3  Advocates for freedom of belief and expression...   \n",
       "4  Runs a popular blog discussing religion, athei...   \n",
       "\n",
       "                   education                    major  \\\n",
       "0  EducationLevels.BACHELORS               journalism   \n",
       "1        EducationLevels.PHD               philosophy   \n",
       "2  EducationLevels.BACHELORS         computer science   \n",
       "3    EducationLevels.MASTERS  international relations   \n",
       "4  EducationLevels.BACHELORS                  english   \n",
       "\n",
       "                                            location  \\\n",
       "0  {'city': 'Austin', 'state_or_province': 'Texas...   \n",
       "1  {'city': 'Berkeley', 'state_or_province': 'Cal...   \n",
       "2  {'city': 'Seattle', 'state_or_province': 'Wash...   \n",
       "3  {'city': 'New York', 'state_or_province': 'New...   \n",
       "4  {'city': 'Denver', 'state_or_province': 'Color...   \n",
       "\n",
       "                                             article  is_relevant  \\\n",
       "0  From : bil @ okcforum.osrhe.edu ( Bill Conner ...         True   \n",
       "1  From : lundby @ rtsg.mot.com ( Walter F. Lundb...        False   \n",
       "2  From : I3150101 @ dbstu1.rz.tu-bs.de ( Benedik...         True   \n",
       "3  Subject : Space FAQ 01/15 - Introduction From ...        False   \n",
       "4  From : mangoe @ cs.umd.edu ( Charley Wingate )...         True   \n",
       "\n",
       "                        job_description_preprocessed      city  \\\n",
       "0  Writes article various social topic , includin...    austin   \n",
       "1  Teaches course philosophy , including metaphys...  berkeley   \n",
       "2  Develops mobile application focus social netwo...   seattle   \n",
       "3  Advocates freedom belief expression around wor...  new york   \n",
       "4  Runs popular blog discussing religion , atheis...    denver   \n",
       "\n",
       "  state_or_province country  \n",
       "0             texas     usa  \n",
       "1        california     usa  \n",
       "2        washington     usa  \n",
       "3          new york     usa  \n",
       "4          colorado     usa  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple preprocessing for occupation, industry, major\n",
    "shorter_text_fields = ['occupation', 'industry', 'major']\n",
    "for field in shorter_text_fields:\n",
    "    df[field] = df[field].apply(preprocess_shorter_text)\n",
    "    \n",
    "# preprocessing for longer text fields\n",
    "df['job_description_preprocessed'] = df['job_description'].apply(preprocess_longer_text)\n",
    "df['article'] = df['article'].apply(preprocess_longer_text)\n",
    "    \n",
    "# flatten location\n",
    "df['city'] = df['location'].apply(lambda x: preprocess_shorter_text(x['city']))\n",
    "df['state_or_province'] = df['location'].apply(lambda x: preprocess_shorter_text(x['state_or_province']))\n",
    "df['country'] = df['location'].apply(lambda x: preprocess_shorter_text(x['country']))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting models to the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract numerical and categorical features from the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# vectorization for job description\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_job_description = vectorizer.fit_transform(df['job_description_preprocessed'])\n",
    "X_article = vectorizer.fit_transform(df['article'])\n",
    "\n",
    "# one-hot encoding for education\n",
    "X_education = pd.get_dummies(df['education'])\n",
    "\n",
    "# count vectorize occupation\n",
    "X_occupation = CountVectorizer()\n",
    "\n",
    "# bag of words features\n",
    "bow_fields = ['occupation', 'industry', 'major', 'city', 'state_or_province', 'country']\n",
    "bow_features = {}\n",
    "for field in bow_fields:\n",
    "    vectorizer = CountVectorizer()\n",
    "    bow_features[field] = vectorizer.fit_transform(df[field])\n",
    "    \n",
    "# combine covariates\n",
    "X_job_description_sparse = sp.csr_matrix(X_job_description)\n",
    "X_article_sparse = sp.csr_matrix(X_article)\n",
    "X_categorical_sparse = sp.csr_matrix(X_education)\n",
    "X_combined = sp.hstack([X_job_description_sparse, X_article_sparse, X_categorical_sparse] + [bow_features[field] for field in bow_fields])\n",
    "\n",
    "# extract targets\n",
    "y = df['is_relevant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we fit supervised machine learning models with binary outputs. The outputs correspond to True/False depending on whether the article in the input is relevant to the profile in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression average prediction score: 0.8841\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# logistic regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000, random_state=1)\n",
    "\n",
    "# 6-fold cross validation\n",
    "cv_logistic = cross_val_score(logistic_model, X_combined, y, cv=6)\n",
    "print(f\"Logistic regression average prediction score: {cv_logistic.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes average prediction score: 0.8841\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# bernoulli bayes model (binary classification)\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# 6-fold cross validation\n",
    "cv_nb = cross_val_score(nb, X_combined, y, cv=6)\n",
    "print(f\"Naive Bayes average prediction score: {cv_nb.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree average prediction score: 0.7785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# 6-fold cross validation\n",
    "cv_dt = cross_val_score(dt, X_combined, y, cv=6)\n",
    "print(f\"Decision tree average prediction score: {cv_dt.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support vector machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM average prediction score: 0.8841\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(random_state=1)\n",
    "\n",
    "# 6-fold cross validation\n",
    "cv_svm = cross_val_score(svm, X_combined, y, cv=6)\n",
    "print(f\"SVM average prediction score: {cv_svm.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change if don't want to save metrics to tables/supervised\n",
    "SAVE_METRICS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model metrics\n",
    "df_pairwise = pd.DataFrame(index=['Logistic', 'Naive Bayes', 'Decision tree', 'SVM'], \n",
    "                             columns=['Average prediction score'])\n",
    "df_pairwise.loc['Logistic', :] = cv_logistic.mean()\n",
    "df_pairwise.loc['Naive Bayes', :] = cv_nb.mean()\n",
    "df_pairwise.loc['Decision tree', :] = cv_dt.mean()\n",
    "df_pairwise.loc['SVM', :] = cv_svm.mean()\n",
    "\n",
    "if SAVE_METRICS:\n",
    "    df_pairwise.to_csv('../tables/supervised/supervised_scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
