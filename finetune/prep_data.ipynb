{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "cats = ['alt.atheism', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'sci.med', 'rec.sport.hockey', 'sci.space', 'soc.religion.christian', 'talk.politics.guns']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats, remove=(\"headers\", \"footers\"), )\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=cats, remove=(\"headers\", \"footers\"), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5184"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "import enum\n",
    "\n",
    "class EducationLevels(str, enum.Enum):\n",
    "    HIGH_SCHOOL = \"high_school\"\n",
    "    BACHELORS = \"bachelors\"\n",
    "    MASTERS = \"masters\"\n",
    "    PHD = \"phd\"\n",
    "    NONE = \"none\"\n",
    "\n",
    "class Location(BaseModel):\n",
    "    city: str\n",
    "    state_or_province: str\n",
    "    country: str\n",
    "\n",
    "class FakeProfile(BaseModel):\n",
    "    name: str\n",
    "    occupation: str\n",
    "    industry: str\n",
    "    job_description: str\n",
    "    education: EducationLevels\n",
    "    major: Optional[str] = Field(default=None)\n",
    "    location: Location\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, data: str):\n",
    "        return cls(**json.loads(data))\n",
    "\n",
    "\n",
    "class FakeProfiles(BaseModel):\n",
    "    profiles: List[FakeProfile]\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, data: str):\n",
    "        return cls(**json.loads(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_data = {}\n",
    "for news_group in cats:\n",
    "    with open(f\"../fake_profiles/{news_group.replace('.', '_')}.json\", \"r\") as f:\n",
    "        profiles_data[news_group] = FakeProfiles.from_json(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.sport.hockey', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'alt.atheism',\n",
       " 1: 'comp.windows.x',\n",
       " 2: 'misc.forsale',\n",
       " 3: 'rec.autos',\n",
       " 4: 'rec.sport.hockey',\n",
       " 5: 'sci.med',\n",
       " 6: 'sci.space',\n",
       " 7: 'soc.religion.christian',\n",
       " 8: 'talk.politics.guns'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(newsgroups_train.target_names)\n",
    "target_to_name = {i: name for i, name in enumerate(newsgroups_train.target_names)}\n",
    "target_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Now available: xvertext 4.0 \\n--------------\\n\\nSummary                                  \\n-------\\nxvertext provides you with four functions to draw strings at any angle in   \\nan X window (previous versions were limited to vertical text). Rotation  \\nis still achieved using XImages, but the notion of rotating a whole font\\nfirst has been dropped.\\n\\nWhat's new?\\n-----------\\nI've added a cache which keeps a copy of previously rotated strings - thus\\nspeeding up redraws.\\n\\nWhere can I get it? \\n-------------------\\ncomp.sources.x (soon...)\\nexport.lcs.mit.edu : contrib/xvertext.4.0.shar.Z  (now)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def preprocess(x: str) -> str:\n",
    "    x = x.replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"\\r\", \" \")\n",
    "\n",
    "    # Remove emails\n",
    "    x = re.sub(r\"\\S*@\\S*\\s?\", \"\", x)\n",
    "\n",
    "    # Remove special characters\n",
    "    x = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", x)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    x = re.sub(\" +\", \" \", x)\n",
    "\n",
    "    return x.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "profile_article_pairs = []\n",
    "for profile_group, profiles in profiles_data.items():\n",
    "    positive_cases = []\n",
    "    negative_cases = []\n",
    "    for profile in profiles.profiles:\n",
    "        for (idx, article) in enumerate(newsgroups_train.data):\n",
    "            article = preprocess(article)\n",
    "            if len(article) <= 1000:\n",
    "                if profile_group == target_to_name[newsgroups_train.target[idx]]:\n",
    "                    positive_cases.append((profile, article, 1))\n",
    "                else:\n",
    "                    negative_cases.append((profile, article, 0))\n",
    "    # Randomly sample equal amount of negative cases\n",
    "    positive_cases = random.sample(positive_cases, len(positive_cases)//2)\n",
    "    negative_cases = random.sample(negative_cases, len(positive_cases))\n",
    "    profile_article_pairs.extend(positive_cases + negative_cases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65482"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(profile_article_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profile_text(profile: FakeProfile):\n",
    "    return f\"{profile.name} is a {profile.occupation} in the {profile.industry} industry. {profile.job_description} {profile.name} has a {profile.education} degree in {profile.major} from {profile.location.city}, {profile.location.state_or_province}, {profile.location.country}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, and test\n",
    "random.shuffle(profile_article_pairs)\n",
    "train_cutoff = int(len(profile_article_pairs) * 0.8)\n",
    "validation_cutoff = int(len(profile_article_pairs) * 0.9)\n",
    "train_pairs = profile_article_pairs[:train_cutoff]\n",
    "validation_pairs = profile_article_pairs[train_cutoff:validation_cutoff]\n",
    "test_pairs = profile_article_pairs[validation_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_sets = [(train_pairs, 'train.jsonl'), (validation_pairs, 'valid.jsonl'), (test_pairs, 'test.jsonl')]\n",
    "\n",
    "for data_set, file_name in data_sets:\n",
    "    with open(file_name, 'w') as f:\n",
    "        for profile, article, relevance in data_set:\n",
    "            data = {\n",
    "                \"text\": f\"User Profile: {get_profile_text(profile)}. Article: {article}. Relevant: {True if relevance == 1 else False}\"\n",
    "            }\n",
    "            f.write(json.dumps(data) + '\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
